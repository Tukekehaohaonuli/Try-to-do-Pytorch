{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import d2lzh_pytorch as d2l\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "(corpus_indices,char_to_idx,idx_to_char,vocab_size)=d2l.load_data_jay_lyrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#产生bat_size个词的向量\n",
    "def one_hot(x,n_class,dtype=torch.float32):\n",
    "    x=x.long()\n",
    "    res=torch.zeros(x.shape[0],n_class,dtype=dtype,device=x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res\n",
    "\n",
    "x=torch.tensor([0,2])\n",
    "one_hot(x,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027])\n"
     ]
    }
   ],
   "source": [
    "#比如（2，5） 即产生5个batch_size个词的列表\n",
    "def to_onehot(X,n_class):\n",
    "    return [one_hot(X[:,i],n_class) for i in range(X.shape[1])]\n",
    "#=\n",
    "X=torch.arange(10).view(2,5)\n",
    "inputs=to_onehot(X,vocab_size)\n",
    "print(len(inputs),inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will use cuda\n"
     ]
    }
   ],
   "source": [
    "num_inputs,num_hiddens,num_outputs=vocab_size,256,vocab_size\n",
    "print('will use',device)\n",
    "\n",
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts=torch.tensor(np.random.normal(0,0.01,size=shape),device=device,dtype=torch.float32)\n",
    "        return torch.nn.Parameter(ts,requires_grad=True)\n",
    "    \n",
    "    W_xh=_one((num_inputs,num_hiddens))\n",
    "    W_hh=_one((num_hiddens,num_hiddens))\n",
    "    b_h=torch.nn.Parameter(torch.zeros(num_hiddens,device=device,requires_grad=True))\n",
    "    W_hq=_one((num_hiddens,num_outputs))\n",
    "    b_q=torch.nn.Parameter(torch.zeros(num_outputs,device=device,requires_grad=True))\n",
    "    return nn.ParameterList([W_xh,W_hh,b_h,W_hq,b_q])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs,state,params):\n",
    "    W_xh,W_hh,b_h,W_hq,b_q=params\n",
    "    H, =state  \n",
    "    outputs=[]\n",
    "    for X in inputs:\n",
    "        H=torch.tanh(torch.matmul(X,W_xh)+torch.matmul(H,W_hh)+b_h)\n",
    "        Y=torch.matmul(H,W_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return outputs,(H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "state=init_rnn_state(X.shape[0],num_hiddens,device)\n",
    "inputs=to_onehot(X.to(device),vocab_size)\n",
    "params=get_params()\n",
    "outputs,state_new=rnn(inputs,state,params)\n",
    "print(len(outputs),outputs[0].shape,state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(prefix,num_chars,rnn,params,init_rnn_state,\n",
    "               num_hiddens,vocab_size,device,idx_to_char,char_to_idx):\n",
    "    state=init_rnn_state(1,num_hiddens,device)\n",
    "    output=[char_to_idx[prefix[0]]]  #首个字符对应的索引\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X=to_onehot(torch.tensor([[output[-1]]],device=device),vocab_size)\n",
    "        (Y,state)=rnn(X,state,params)\n",
    "        if t<len(prefix)-1:\n",
    "            output.aapend(char_to_idx([prefix[t+1]]))\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
